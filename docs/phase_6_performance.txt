Phase 6 — Profiling & Optimization (In Progress)

Note
These logs were reviewed and lightly reorganized after a break from the project.
No results, measurements, or conclusions were changed.
The purpose of the rewrite is to improve readability and structure only.

Goal
The goal of Phase 6 is to identify performance hotspots in the N-body simulation
before attempting further optimization.
All optimization decisions in this phase are based on measured data rather than assumptions.

General Approach
Profiling is done using Python’s built-in cProfile.
The full simulation pipeline is profiled, including solver, integrator, and diagnostics.
Results are sorted by cumulative runtime to identify the dominant cost areas.
Both Direct and Barnes–Hut solvers are profiled separately.
Real runtime measurements (without profiling) are used to confirm improvements,
since profiling overhead can distort results for recursive code.


--- Direct Solver — Initial Profiling


Setup
Integrator: Leapfrog (Velocity Verlet)
Solver: Direct O(N^2)
N = 300
Steps = 300
dt = 2e-3
Softening = 1e-3

Results
Total runtime was approximately 95 seconds under profiling.
Most of the runtime is spent inside physics.compute_accelerations.
This matches the expected O(N^2) scaling of the Direct solver.
Leapfrog integration adds additional cost due to repeated force evaluations
and synchronization.
Diagnostics such as energy, momentum, and center-of-mass tracking contribute
noticeable but smaller overhead.
State copying and object creation appear in the profile but are not the main hotspots.

Interpretation
The Direct solver behaves exactly as expected from theory.
Pairwise force computation dominates runtime and defines the performance limit.
This provides a correct baseline for comparison in Phase 6.


--- Barnes–Hut Solver — Initial Profiling


Setup
Integrator: Leapfrog (Velocity Verlet)
Solver: Barnes–Hut Octree (theta = 0.7)
N = 1000
Steps = 300
dt = 2e-3
Softening = 1e-3

Results
Total runtime was approximately 1038 seconds under profiling.
Runtime is dominated by recursive tree traversal during force evaluation.
OctreeNode.compute_accelerations accounts for the majority of cumulative runtime.
Tree construction steps such as insert, subdivide, and mass or center-of-mass
updates contribute noticeable but smaller overhead.
Function call counts are extremely high due to recursion and repeated node visits.
Leapfrog integration increases traversal cost because accelerations are evaluated
multiple times per timestep.
Diagnostics are expensive but not the dominant cost.

Interpretation
Although Barnes–Hut has better asymptotic scaling, Python-level overhead from
recursion, object handling, and attribute access significantly reduces its
practical performance advantage at this stage.


--- Profiling With Diagnostics Disabled


Direct Solver
Total runtime was approximately 72 seconds.
The main hotspot remains physics.compute_accelerations.
This confirms that Direct solver performance is dominated by the O(N^2) force loop.
Integrator overhead is present but secondary.

Barnes–Hut Solver
Total runtime was approximately 760 seconds.
Function call counts remain extremely high due to recursive traversal.
OctreeNode.compute_accelerations dominates cumulative runtime.
Tree construction costs are visible but not the primary hotspots.
Profiling overhead disproportionately affects Barnes–Hut because of recursion.

Interpretation
Disabling diagnostics confirms that:
Direct solver cost comes from pairwise force computation.
Barnes–Hut cost comes from Python recursion and object-level traversal.
The algorithmic advantage of Barnes–Hut is masked by Python overhead under profiling.


--- Optimization Attempt 1 — Barnes–Hut Tree Traversal


Change
Small local optimizations were made inside OctreeNode.compute_accelerations:
Frequently accessed attributes were cached into local variables.
Duplicate distance calculations were removed.
Softening squared was precomputed.
Early returns were added in approximation cases.

Reason
Profiling showed that OctreeNode.compute_accelerations is the dominant hotspot.
The goal was to reduce Python overhead per call without changing the algorithm.

Expected Effect
A small reduction in runtime due to fewer attribute lookups and repeated math
operations in a heavily used function.

Verification
Barnes–Hut was run with N = 10 and diagnostics enabled after the change.
The simulation completed normally and diagnostics behaved as expected.


--- Profiling After Optimization Attempt 1


Results
Re-profiled Barnes–Hut with N = 1000 and diagnostics enabled.
Time spent per call inside compute_accelerations decreased.
Overall profiling runtime increased.
Function call count increased significantly.

Interpretation
The optimization reduced work per call but did not reduce the number of
recursive calls.
Profiler overhead increased because of the higher call count, masking real
runtime improvements.


--- Real Runtime Measurements (No Profiling)


Setup
Identical configuration to profiling runs, but without cProfile enabled.

Results
Original Barnes–Hut implementation runtime was approximately 349.5 seconds.
Optimized implementation runtime was approximately 233.1 seconds.
This corresponds to an improvement of roughly 33 percent.

Interpretation
Although profiling results were unclear, real runtime measurements show a
substantial speedup.
Reducing per-call overhead in compute_accelerations is effective.

Conclusion
The optimization should be kept.
Further improvements should focus on reducing recursion depth and total
function call count.


--- Additional Verification


Barnes–Hut was run with N = 50 and diagnostics enabled after the changes.
The simulation completed normally with finite drift values and no crashes.

Testing Notes
Timing tests were moved from profile_phase6.py to time_barnes.py for the rest of Phase 6.


--- Timing Recheck


Setup
N = 1000
Steps = 300
Theta = 0.7
Diagnostics disabled

Result
Measured runtime was approximately 351.9 seconds.

Note
This runtime is similar to the earlier baseline of about 349.5 seconds.
The difference may be due to configuration differences or missing cache effects.
Further checks are required to confirm identical conditions.


--- Clarification Profiling Run


Purpose
This profiling run was performed to remove confusion about the main Barnes–Hut
performance hotspots before continuing optimization.

Results
The majority of total runtime is spent inside OctreeNode.compute_accelerations.
Tree construction accounts for a much smaller portion of the total runtime.

Interpretation
Caching the octree alone would provide limited benefit.
The primary performance issue is repeated tree traversal for force evaluation.

Conclusion
Phase 6 optimization should focus on reducing the number of Barnes–Hut force
evaluations per timestep, rather than only optimizing tree construction.
